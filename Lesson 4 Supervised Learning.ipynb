{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Supervised Learning with Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Machine Learning is about data. Data is either labeled or not.\n",
    "\n",
    "## Labeled Data\n",
    "\n",
    "Labeled data is data that has an outcome or a title. For example, in the Iris Flower Dataset we looked at in the introduction, we have labels/outcomes. This dataset is called labeled because we have predictors/features, which are the measurements of the petals and the sepals. The label is the species/name of the flower.\n",
    "\n",
    "Another example is the imagenet dataset hosted at http://www.image-net.org/. This is a database of 14 million images with labels.\n",
    "\n",
    "### Structured Data\n",
    "A structured dataset is one in which the meaning of the data does not change if you change the order of its features or examples. The Iris Flower Dataset is a structured dataset because it does not matter the order of the petal width and petal length in the dataset. How you arrange the fields does not change the information you are passing across. Here is the table again.\n",
    "\n",
    "![structured data](assets/Iris/3.jpg)\n",
    "\n",
    "### Unstructured Data\n",
    "Unstructured data is one in which the order of the data cannot be changed without altering the meaning of the data. Examples of this are images, sound files, and video files. Images are usually stored as 2-D or 3-D arrays (or tensors). A 2-D array is a table. However, if you had an image with 28 columns and 28 rows, you couldn't alternate the 10th and 20th columns of the array without changing the meaning of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Labels\n",
    "\n",
    "In supervised learning, there are two types of labels.\n",
    "\n",
    "## Categorical Labels\n",
    "In the example of imagenet, every image has a label. In the example of the Iris dataset, every example has a label, which is the specie of the flower. These are both examples of categorical labels. In essence, the label can have a value that falls within a limited range.\n",
    "\n",
    "While the labels make sense to us, they are usually stored in one of two formats for the computer to work with. The first format uses a numerical encoding. An example of this is:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Species</th><th>Encoding</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. setosa</td><td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. versicolor</td><td>1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. verginica</td><td>2</td>\n",
    "    </tr>\n",
    "</table>\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second format uses a one-hot encoding. In this format, a column exists for each option. The column is set to 1 if the entry is for that species, and 0 otherwise. An example of this is:\n",
    "\n",
    "<table>\n",
    "    <tr>\n",
    "        <th>Species</th><th>is_setosa</th><th>is_versicolor</th><th>is_verginica</th>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. setosa</td><td>1</td><td>0</td><td>0<td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. versicolor</td><td>0</td><td>1</td><td>0</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "        <td>I. verginica</td><td>0</td><td>0</td><td>1</td>\n",
    "    </tr>\n",
    "</table>\n",
    "\n",
    "You might notice that the first format tells you the column to have a 1 in for the second format. The one-hot encoding format is useful because it simplifies vector multiplications. It is even more important because it clarifies relationships. When you look at the number representation, you might be tempted to think that the different species have a linear relationship, and that one specie is bigger than the preceding one. One-hot encoding clarifies the relationship between species.\n",
    "\n",
    "The one-hot encoding is used for providing input to prediction models, and for getting output.\n",
    "\n",
    "Output is provided either as a value that is 0 or 1, or as a probability, during predictions. The model computes the probability of each column during prediction, and passes it out either directly, so you can see the probabilities, or uses an `argmax()` to tell you which column has the highest probability.\n",
    "\n",
    "When the output of your model is a categorical column, your model is said to perform **classification**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Numerical Labels\n",
    "\n",
    "Let's look at the Iris dataset again. If we decided that we wanted to predict the petal length given the species and three other measurements, our label would be a continuous numeral. This type of model is said to perform **regression**.\n",
    "\n",
    "# Algorithms\n",
    "Supervised Learning algorithms fall into two classes: **classification** and **regression**\n",
    "\n",
    "## Classification\n",
    "A classification problem is one in which you predict the probability of an event or a class. For example, predicting whether it is going to rain or not when given certain details like temperature and humidity, or predicting what class of animal you are dealing with when given the photo of the animal. The following algorithms are commonly used when building classification models.\n",
    "\n",
    "### Logistic Regression\n",
    "### Decision Trees\n",
    "### Nearest Neighbors\n",
    "### Random Forests\n",
    "\n",
    "## Regression\n",
    "A regression problem is one in which you predict an actual value, such as a temperature or humidity, when given certain features. The following algorithms are commonly used when building regression models.\n",
    "\n",
    "### Linear Regression\n",
    "### Lasso Regression\n",
    "### Ridge Regression\n",
    "### ElasticNet Regression\n",
    "### Kernel Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Networks\n",
    "\n",
    "Neural Networks are frequently used for both classification and regression. There are a lot of neural network architectures, but we will focus on only a few starting from Lesson 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features\n",
    "\n",
    "Recall our Iris Dataset\n",
    "\n",
    "![structured data](assets/Iris/3.jpg)\n",
    "\n",
    "The columns of input data `Sepal length`, `Sepal width`, `Petal length` and `Petal width` are called features. Features generally fall into numerical and categorical. The four features above are obviously numerical.\n",
    "\n",
    "When dealing with data, it is normal to pre-process. These steps include cleaning the data, finding missing data and outliers. Outliers might be dropped, while missing data are handled specially depending on the type of data as well as the domain. In entry-level situations, it is common to carry out data imputation, which is simply filling in missing values. For categorical variables, the most common value is used. For numerical values, the mean or median is used.\n",
    "\n",
    "# Feature Engineering\n",
    "\n",
    "In Machine Learning, it is frequently the case that certain features are derived from the features that are given. This is called Feature Engineering. Some of the operations that occur under feature engineering include:\n",
    "* binning\n",
    "* one-hot encoding\n",
    "* embedding\n",
    "* feature crosses\n",
    "\n",
    "### Binning\n",
    "Binning is done when you want to convert a continuous numerical feature into groups. For example, you might convert shirt sizes from chest measurements into small, medium, and large. This is useful for algorithms perform comparisons. This way, instead of asking whether the shirt size is below a particular figure, and then continuing for all values in the range of the shirt size, the algorithm checks whether the shirt is small, medium or large.\n",
    "\n",
    "### Feature Crosses\n",
    "Feature crosses are created by combining features. There are two approaches:\n",
    "* combining numeric features for polynomial regression: for example, to create the square of a feature\n",
    "* combining categorical or binned features: for example, to create stock keeping units by combining size and color.\n",
    "\n",
    "### One-Hot Encoding\n",
    "This let's us numerically encode categorical features in an array format. Each category is converted into a column, and the value of the column is set to 1 if the category is the value of the column, and 0 otherwise. This format speeds up numerical computations, but as you might have imagined, can make your matrices (or tensors) extremely large. For example, if you represented the English dictionary of words as a one-hot encoding, you could easily end up with a matrix with 1 million entries. That is just large!\n",
    "\n",
    "### Embedding\n",
    "Embedding vectors are created from a one-hot encoding by reducing the dimension of the matrix. When this happens, a new vector representation is learnt with a much smaller number of columns. This time around, instead of 1s and 0s, each entry is a floating point number. You can imagine it as both a magnitude and a direction, with the resulting vector representation placing words that are similarly used close together. The one-hot encoding above might be represented as a vector of size 50!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss Functions\n",
    "A loss is a measure of how well your model is performing. It is important to state that all models are wrong, you just need to find the most useful model to work with for your problem and data. That essentially means that a _golden model_ does not exist.\n",
    "\n",
    "Loss functions are computed for both classification and regression, but we will use a regression to explain. Imagine you are predicting the selling price of items in a catalog. Your training data has both features and a label. The label that comes with your training data is called the ground truth `y`. The price that you predict is called `y_pred`. For every item you need to predict, the difference between `y` and `y_pred` is called the **loss** or **cost**, because this is how much you lose when you make use of that model. Mathematically, we write this as $L = \\sum{y - \\hat{y}}$\n",
    "\n",
    "But, that particular equation is not used because of positive and negative differences. As a result, we take the absolute values of the differences. Also, we take an average by dividing the total value by the number of observations we are working with. This loss function is called **Mean Absolute Error** (MAE) and is written as $L = \\frac{\\sum{\\left|y - \\hat{y} \\right|}}{n}$\n",
    "\n",
    "This is not the only loss function for regression. Instead of the absolute value, we could take the square of the differences, and then take the root of the summation, and divide by the number of observations. This is called a **Root Mean Square Error** (RMSE).\n",
    "\n",
    "When performing classification, the loss function is a measure of the magnitude of the probability of a wrong prediction. If the prediction is correct, then there is no penalty. However, when the prediction is wrong, the higher the probability, the greater the cost. This is called **log loss**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Criteria\n",
    "Every Machine Learning problem has a specific domain. This could be automotive, agriculture, healthcare, or something else. As a result, the performance of a model that is developed has to be defined by an evaluation metric. \n",
    "\n",
    "For regression problems, the metric could be given as any one of Mean Absolute Error, Root Mean Squared Error, or some other metric that will be given as a function of the ground truth and the predictions.\n",
    "\n",
    "For classification problems, this is given as any of precision, recall, accuracy, AUC, and others. To explain these, we need to introduce the confusion matrix.\n",
    "\n",
    "![confusion-matrix](assets/confusion-matrix.png)\n",
    "\n",
    "The confusion matrix compares the predictions of the model to the ground truth. As usual, it is easiest to use binary classification, which is what we have on the image above. There are four measures:\n",
    "* True Positive (TP): This is the number of times the model predicts the class of an observation to be 1 and it is actually 1.\n",
    "* False Positive (FP): This is the number of times the model predicts the class of an observation to be 1 when it is actually 0.\n",
    "* True Negative (TN): This is the number of times the model predicts the class of an observation to be 0 when it is actually 0.\n",
    "* False Negative (FN): This is the number of times the model predicts the class of an observation to be 0 when it is actually 1.\n",
    "\n",
    "To put the measures above in concrete terms, imagine a situation in which your model is trying to detect tuberculosis from a chest x-ray.\n",
    "* True Positive is when the model predicts the presence of infection when there is actually an infection.\n",
    "* False Positive is when the model predicts the presence of infecton when there is none.\n",
    "* True Negative is when the model predicts the absence of infection and there is none.\n",
    "* False Negative is when the model predicts the absence of infection when there is.\n",
    "\n",
    "Take a moment to think about the impact of the predictions. TP and TN are all well and good, but what happens to FP and FN? FP get treated when they actually have no disease, while FN don't get treated when they do have a disease. This is where it becomes important to work with domain experts to determine what value to optimize based on the side effect of treating a healthy person versus the fall-out of not treating an infected person.\n",
    "\n",
    "If you are still wondering how important this is, take out tuberculosis and put in Ebola! What would you do? There is no answer to the question. You have to do what the health professionals say is important. They will tell you what measure to optimize/minimize. For example, they might say \"we don't want any False Negatives\". Then, you will need to tune the model to meet the evaluation criteria.\n",
    "\n",
    "**True Positive Rate** is defined as $TPR = \\frac{TP}{TP + FN}$\n",
    "\n",
    "**False Negative Rate** is defined as $FNR = 1 - TPR$\n",
    "\n",
    "**True Negative Rate** is define as $TNR = \\frac{TN}{TN + FP}$\n",
    "\n",
    "**False Positive Rate** is defined as $FPR = 1 - TNR$\n",
    "\n",
    "Four more metrics to be aware of are:\n",
    "\n",
    "**Precision** is $\\frac{TP}{TP + FP}$\n",
    "\n",
    "**Recall** is $\\frac{TP}{TP + FN}$\n",
    "\n",
    "**Accuracy** is $\\frac{TP + TN}{TP + TN + FP + FN}$\n",
    "\n",
    "**F1 Score** is $\\frac{2 * TP}{2*TP + FP + FN}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation\n",
    "\n",
    "We will be implementing our solutions using two libraries/frameworks:\n",
    "\n",
    "* scikit-learn: this is a library that has implemented a large number of Machine Learning algorithms.\n",
    "* TensorFlow: this is a numerical computation library that let's you implement Machine Learning and Neural Network algorithms in a few lines of code.\n",
    "\n",
    "In the next lesson, we will implement some linear models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
