{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Models\n",
    "\n",
    "In this lesson, we will look at regression and classification using linear models. For regression, we will be predicting housing prices using the Boston Housing dataset. For classification, we will be predicting survival using the Titanic dataset.\n",
    "\n",
    "We will make use of both scikit-learn and TensorFlow."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in the Boston housing data\n",
    "boston_df = pd.read_csv('assets/Boston/train.csv', index_col='ID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 333 entries, 1 to 506\n",
      "Data columns (total 14 columns):\n",
      "crim       333 non-null float64\n",
      "zn         333 non-null float64\n",
      "indus      333 non-null float64\n",
      "chas       333 non-null int64\n",
      "nox        333 non-null float64\n",
      "rm         333 non-null float64\n",
      "age        333 non-null float64\n",
      "dis        333 non-null float64\n",
      "rad        333 non-null int64\n",
      "tax        333 non-null int64\n",
      "ptratio    333 non-null float64\n",
      "black      333 non-null float64\n",
      "lstat      333 non-null float64\n",
      "medv       333 non-null float64\n",
      "dtypes: float64(11), int64(3)\n",
      "memory usage: 39.0 KB\n"
     ]
    }
   ],
   "source": [
    "# what columns are contained in this dataset? what are the types? are there any null values?\n",
    "boston_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the data has 333 records, all columns are numeric, and we have no null entries. It's our lucky day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1</td>\n",
       "      <td>296</td>\n",
       "      <td>15.3</td>\n",
       "      <td>396.90</td>\n",
       "      <td>4.98</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2</td>\n",
       "      <td>242</td>\n",
       "      <td>17.8</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.14</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>394.63</td>\n",
       "      <td>2.94</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3</td>\n",
       "      <td>222</td>\n",
       "      <td>18.7</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.33</td>\n",
       "      <td>36.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.08829</td>\n",
       "      <td>12.5</td>\n",
       "      <td>7.87</td>\n",
       "      <td>0</td>\n",
       "      <td>0.524</td>\n",
       "      <td>6.012</td>\n",
       "      <td>66.6</td>\n",
       "      <td>5.5605</td>\n",
       "      <td>5</td>\n",
       "      <td>311</td>\n",
       "      <td>15.2</td>\n",
       "      <td>395.60</td>\n",
       "      <td>12.43</td>\n",
       "      <td>22.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       crim    zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "ID                                                                              \n",
       "1   0.00632  18.0   2.31     0  0.538  6.575  65.2  4.0900    1  296     15.3   \n",
       "2   0.02731   0.0   7.07     0  0.469  6.421  78.9  4.9671    2  242     17.8   \n",
       "4   0.03237   0.0   2.18     0  0.458  6.998  45.8  6.0622    3  222     18.7   \n",
       "5   0.06905   0.0   2.18     0  0.458  7.147  54.2  6.0622    3  222     18.7   \n",
       "7   0.08829  12.5   7.87     0  0.524  6.012  66.6  5.5605    5  311     15.2   \n",
       "\n",
       "     black  lstat  medv  \n",
       "ID                       \n",
       "1   396.90   4.98  24.0  \n",
       "2   396.90   9.14  21.6  \n",
       "4   394.63   2.94  33.4  \n",
       "5   396.90   5.33  36.2  \n",
       "7   395.60  12.43  22.9  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# take a peak at the records to see what they look like\n",
    "boston_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>crim</th>\n",
       "      <th>zn</th>\n",
       "      <th>indus</th>\n",
       "      <th>chas</th>\n",
       "      <th>nox</th>\n",
       "      <th>rm</th>\n",
       "      <th>age</th>\n",
       "      <th>dis</th>\n",
       "      <th>rad</th>\n",
       "      <th>tax</th>\n",
       "      <th>ptratio</th>\n",
       "      <th>black</th>\n",
       "      <th>lstat</th>\n",
       "      <th>medv</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.17783</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.69</td>\n",
       "      <td>0</td>\n",
       "      <td>0.585</td>\n",
       "      <td>5.569</td>\n",
       "      <td>73.5</td>\n",
       "      <td>2.3999</td>\n",
       "      <td>6</td>\n",
       "      <td>391</td>\n",
       "      <td>19.2</td>\n",
       "      <td>395.77</td>\n",
       "      <td>15.10</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>391.99</td>\n",
       "      <td>9.67</td>\n",
       "      <td>22.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>9.08</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>5.64</td>\n",
       "      <td>23.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>506</th>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1</td>\n",
       "      <td>273</td>\n",
       "      <td>21.0</td>\n",
       "      <td>396.90</td>\n",
       "      <td>7.88</td>\n",
       "      <td>11.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        crim   zn  indus  chas    nox     rm   age     dis  rad  tax  ptratio  \\\n",
       "ID                                                                              \n",
       "500  0.17783  0.0   9.69     0  0.585  5.569  73.5  2.3999    6  391     19.2   \n",
       "502  0.06263  0.0  11.93     0  0.573  6.593  69.1  2.4786    1  273     21.0   \n",
       "503  0.04527  0.0  11.93     0  0.573  6.120  76.7  2.2875    1  273     21.0   \n",
       "504  0.06076  0.0  11.93     0  0.573  6.976  91.0  2.1675    1  273     21.0   \n",
       "506  0.04741  0.0  11.93     0  0.573  6.030  80.8  2.5050    1  273     21.0   \n",
       "\n",
       "      black  lstat  medv  \n",
       "ID                        \n",
       "500  395.77  15.10  17.5  \n",
       "502  391.99   9.67  22.4  \n",
       "503  396.90   9.08  20.6  \n",
       "504  396.90   5.64  23.9  \n",
       "506  396.90   7.88  11.9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boston_df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scikit-learn\n",
    "our target/label is called `medv`. To use scikit-learn, we will simply split our data into two (a training set and a validation set). The normal ratio is 70% for training and 30% for validation. scikit-learn let's us create this using `train-test-split()`\n",
    "\n",
    "Before splitting, we need to separate our `boston_df` into features and labels!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = boston_df.drop('medv', axis=1) # this returns a DataFrame\n",
    "y = boston_df['medv'] # this returns a Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/envs/tensorflow/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2026: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=42, train_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our training and validation datasets, and are ready to train our first linear model.\n",
    "\n",
    "We will use scikit-learn to build a Linear Regression model using all of our features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "linearModel = LinearRegression()\n",
    "linearModel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_That was simple, we have trained a Machine Learning model!_\n",
    "\n",
    "Is the model any good? We can find out by scoring the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6649640156673967"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModelScore = linearModel.score(X_val, y_val)\n",
    "linearModelScore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can make predictions by calling `predict()` on our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "linearModelPredictions = linearModel.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(linearModelPredictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.26235712e+01,  2.34212241e+01,  2.37586031e+01,  3.23650484e+01,\n",
       "        2.42125794e+01,  1.61880600e+01,  1.87279403e+01,  3.10467105e+01,\n",
       "        1.58209827e+01,  2.39169645e+01,  2.70319068e+01,  2.00346550e+01,\n",
       "        1.93732446e+01,  3.44786844e+01,  2.31527662e+01,  3.53225705e+01,\n",
       "        2.26105398e+01,  1.43837813e+01,  2.66898889e+01,  1.58980379e+01,\n",
       "        3.56766500e+01,  3.17486222e+01,  2.24073651e+01,  2.79839745e+01,\n",
       "        1.55038571e+01,  3.87740295e+01,  2.77790326e+00,  3.99005215e-02,\n",
       "        3.04058173e+01,  1.00014711e+01,  1.88600247e+01,  2.01080332e+01,\n",
       "        2.84773446e+01,  8.81440292e+00,  1.92562123e+01,  1.17036958e+01,\n",
       "        2.65171844e+01,  3.24174746e+00,  1.65123971e+01,  2.49366431e+01,\n",
       "        2.26242956e+01,  2.11199715e+01,  2.46397951e+01,  4.01565956e+01,\n",
       "        3.49345881e+01,  2.18745406e+01,  1.14354196e+01,  2.07182010e+01,\n",
       "        1.27531309e+01,  1.95981203e+01,  1.06047576e+01,  2.92340621e+01,\n",
       "        2.18628778e+01,  1.28274284e+01,  3.31944234e+01, -1.43917351e+00,\n",
       "        1.86307519e+01,  2.74284966e+01,  2.33890327e+01,  3.11652185e+01,\n",
       "        1.79176388e+01,  2.35657717e+01,  1.94444523e+01,  2.73674918e+01,\n",
       "        2.40558626e+01,  1.74449221e+01,  2.67979032e+01,  2.13121283e+01,\n",
       "        2.53245250e+01,  1.79449208e+01,  1.43492469e+01,  2.38269197e+01,\n",
       "        1.84980648e+01,  1.40930696e+01,  2.52537925e+01,  3.48798401e+01,\n",
       "        1.72017423e+01,  2.33497555e+01,  2.09377947e+01,  2.22610444e+01,\n",
       "        2.13231571e+01,  3.08417052e+01,  4.09703272e+01,  1.38926736e+01,\n",
       "        1.08446436e+01,  9.65379195e+00,  1.91488707e+01,  2.06684639e+01,\n",
       "        3.65711747e+01,  1.63389972e+01,  2.00687379e+01,  2.27506914e+01,\n",
       "        2.13863568e+01,  2.14509799e+01,  3.10267600e+01,  1.44346752e+01,\n",
       "        2.04073543e+01,  2.37659930e+01,  1.68656990e+01,  1.50108784e+01,\n",
       "        3.23951443e+01,  1.14677668e+01,  2.08668839e+01,  2.56480818e+01,\n",
       "        3.82654314e+01,  2.01537584e+01,  2.19567523e+01,  2.30069140e+01,\n",
       "        1.63747071e+01,  3.79632802e+01,  1.74608698e+01,  2.20512001e+01,\n",
       "        2.14822867e+01,  3.78557157e+01,  2.66530430e+01,  2.53252314e+01,\n",
       "        3.28957921e+01,  2.89433882e+01,  2.58097853e+01,  2.07948318e+01,\n",
       "        9.98282587e+00,  2.21545649e+01,  1.32296098e+01,  3.11531421e+01,\n",
       "        1.85867740e+01,  1.95386030e+01,  1.35819809e+01,  2.12178409e+01,\n",
       "        2.37785356e+01,  2.78999739e+01, -1.33320535e+00,  1.13003185e+01,\n",
       "        1.50437708e+01,  2.66139876e+01,  3.50195541e+01,  3.35499526e+01,\n",
       "        2.96321338e+01,  2.54649601e+01,  1.31183193e+01,  2.17166507e+01,\n",
       "        3.40307631e+01,  2.10107417e+01,  7.10467701e+00,  9.66007813e+00,\n",
       "        3.09498654e+01,  1.27510961e+01,  5.37534159e+00,  1.73826568e+01,\n",
       "        2.23028649e+01,  2.02300295e+01,  3.22556299e+01,  2.24919175e+01,\n",
       "        3.35125146e+01,  2.12599847e+01,  2.06774056e+01,  3.20991455e+01,\n",
       "        2.29422917e+01,  2.53772792e+01,  3.33221841e+01,  3.40575779e+01,\n",
       "        2.32419725e+01,  2.13979902e+01,  2.19340277e+01,  2.36484226e+01,\n",
       "        2.53682517e+01,  2.22508764e+01,  2.96703366e+01,  3.86266068e+01,\n",
       "        2.73925721e+01,  2.87488279e+01,  2.50707484e+01,  2.55970369e+01,\n",
       "        1.46285455e+01,  2.88757694e+01,  2.74808565e+01,  1.28062366e+01,\n",
       "        2.92856694e+01,  2.02376801e+01,  1.52014678e+01,  1.46272848e+01,\n",
       "        1.37638643e+01,  2.57747337e+01,  2.82917661e+01,  2.44164540e+01,\n",
       "        3.08922139e+01,  3.33638712e+01,  2.16320309e+01,  2.62432047e+01,\n",
       "        1.57685434e+01,  2.51306318e+01,  1.91343599e+01,  1.49598306e+01,\n",
       "        3.53509186e+01,  2.13092289e+01,  3.73978109e+01,  1.75363844e+01,\n",
       "        2.99190456e+01,  1.82463064e+01,  2.22686452e+01,  4.24195859e+01,\n",
       "        3.77042493e+01,  3.50031693e+01, -6.15413931e+00,  2.25455804e+01,\n",
       "        1.34514842e+01,  5.23949272e+00,  3.73880520e+01,  3.66323657e+01,\n",
       "        3.14384020e+01,  2.05088856e+01,  1.74707461e+01,  1.88202635e+01,\n",
       "        2.41746809e+01,  3.14414815e+01,  2.14729758e+01,  2.18454351e+01,\n",
       "        4.13263936e+01,  2.76490173e+01,  3.22272273e+01,  1.96209591e+01,\n",
       "        1.94363205e+01,  2.02679034e+01,  6.45218548e+00,  1.85258290e+01,\n",
       "        1.75118413e+01,  2.23352272e+01,  2.36562009e+01,  1.74152085e+01,\n",
       "        2.30369417e+01,  9.07109037e+00,  2.54498627e+01,  2.97587218e+00,\n",
       "        3.22272791e+01,  2.24567902e+01])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModelPredictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compare our predicted values to our ground truths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y</th>\n",
       "      <th>y_pred</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>24.7</td>\n",
       "      <td>22.623571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>472</th>\n",
       "      <td>19.6</td>\n",
       "      <td>23.421224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>19.8</td>\n",
       "      <td>23.758603</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>27.9</td>\n",
       "      <td>32.365048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>23.9</td>\n",
       "      <td>24.212579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>13.5</td>\n",
       "      <td>16.188060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>11.7</td>\n",
       "      <td>18.727940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>30.7</td>\n",
       "      <td>31.046711</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>17.8</td>\n",
       "      <td>15.820983</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>27.1</td>\n",
       "      <td>23.916965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        y     y_pred\n",
       "ID                  \n",
       "44   24.7  22.623571\n",
       "472  19.6  23.421224\n",
       "109  19.8  23.758603\n",
       "293  27.9  32.365048\n",
       "85   23.9  24.212579\n",
       "458  13.5  16.188060\n",
       "435  11.7  18.727940\n",
       "267  30.7  31.046711\n",
       "317  17.8  15.820983\n",
       "297  27.1  23.916965"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_df = pd.DataFrame({'y': y_val, 'y_pred': linearModelPredictions})\n",
    "comp_df.head(n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In all honesty, we shouldn't be using our eyes to judge. We should use a metric like MAE or RMSE to compare one model to the next! Let's import another function from scikit-learn to give us a hand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5.321052760278853\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, linearModelPredictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that this RMSE does not mean much right now. However, we can make it a baseline. Let's try to improve it.\n",
    "\n",
    "Right now, what we have is a linear model. Let's build a polynomial model. What that means is, we will **engineer** new features. We will keep it simple by taking each feature and crossing it with only itself, essentially creating a square of each feature.\n",
    "\n",
    "`sklearn` makes it easy to create squares of features. To make this work for us, we will make use of **pipelines**. Pipelines make it possible to apply a list of transformations. The particular transformation we will make use of is `PolynomialFeatures`.\n",
    "\n",
    "## Polynomial Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we cross our features, we quickly run into very large numbers. To avoid having to deal with such large numbers, we will scale our features down to a range between 0 and 1. We will make use of `StandardScaler` to accomplish this.\n",
    "\n",
    "Pipelines are made up of steps. We will define our transformations as steps. The steps we define are to scale our data, then create polynomials of degree 2, and then pass all of that to our Linear regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', LinearRegression())\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After defining our steps, we can then create our pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = Pipeline(steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we are ready to treat `pipeline` the same way we treat models. We can train by calling `fit`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scalar', StandardScaler(copy=True, with_mean=True, with_std=True)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('model', LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False))])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyModelPredictions = pipeline.predict(X_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our RMSE to see whether our model is getting better!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 331.8541944770887\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_val, polyModelPredictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our RMSE has got significantly worse! Let's check our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.9999468301332847\n"
     ]
    }
   ],
   "source": [
    "print('Training score: {}'.format(pipeline.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: -1302.1396137052345\n"
     ]
    }
   ],
   "source": [
    "print('Test score: {}'.format(pipeline.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From our training and test score above, we can tell that our model has overfit to the data. We need to introduce one or more tools to fix this.\n",
    "\n",
    "## Fix Overfitting/Variance\n",
    "The popular approaches to reducing variance are:\n",
    "1. Add more data\n",
    "1. Use data augmentation\n",
    "1. Use architectures that generalize well\n",
    "1. Add regularization\n",
    "1. Reduce architecture complexity\n",
    "\n",
    "The first two options are not available to us, so we will try using other architectures, adding regularization, and reducing architecture complexity. Scikit-learn provides three models that provide regularization:\n",
    "* Lasso\n",
    "* Ridge\n",
    "* ElasticNet\n",
    "\n",
    "These models also reduce complexity. `Lasso` reduces model complexity by completely eliminating certain features. `Ridge` reduces model complexity by driving the feature weights to a value very close to 0.\n",
    "\n",
    "# Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Lasso, Ridge, ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scalar', StandardScaler(copy=True, with_mean=True, with_std=True)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('model', Lasso(alpha=0.9, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Lasso(alpha=0.9))\n",
    "]\n",
    "\n",
    "lasso_pipe = Pipeline(steps)\n",
    "lasso_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 4.471162348530323\n"
     ]
    }
   ],
   "source": [
    "lassoModelPredictions = lasso_pipe.predict(X_val)\n",
    "mse = mean_squared_error(y_val, lassoModelPredictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Would you take a look at that! Our RMSE has fixed itself and gone down. Our Lasso model has got rid of our overfitting. Lets take a look at our scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.8172033635115156\n"
     ]
    }
   ],
   "source": [
    "print('Training score: {}'.format(lasso_pipe.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 0.763442237743289\n"
     ]
    }
   ],
   "source": [
    "print('Test score: {}'.format(lasso_pipe.score(X_val, y_val)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training and test scores are now closer. Our overfitting problem has reduced. We can also improve our model by playing around with our regularization parameter `alpha`.\n",
    "\n",
    "# Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "     steps=[('scalar', StandardScaler(copy=True, with_mean=True, with_std=True)), ('poly', PolynomialFeatures(degree=2, include_bias=True, interaction_only=False)), ('model', Ridge(alpha=0.9, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001))])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steps = [\n",
    "    ('scalar', StandardScaler()),\n",
    "    ('poly', PolynomialFeatures(degree=2)),\n",
    "    ('model', Ridge(alpha=0.9))\n",
    "]\n",
    "\n",
    "ridge_pipe = Pipeline(steps)\n",
    "ridge_pipe.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 5.8229374742527495\n"
     ]
    }
   ],
   "source": [
    "ridgeModelPredictions = ridge_pipe.predict(X_val)\n",
    "mse = mean_squared_error(y_val, ridgeModelPredictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this particular dataset, `Ridge` is not as good as `Lasso`, but for other datasets, the situation might be different.\n",
    "\n",
    "We will leave the implementation of `ElasticNet` to the student."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow\n",
    "\n",
    "TensorFlow supports the creation of Linear Models using the `Estimator` API. Using TensorFlow requires some additional preparation because of the robust nature of solutions created using it. TensorFlow supports data that does not fit into your computer memory, and also supports training models over a distributed number of processors. At first, TensorFlow appears to be extremely verbose when compared to other libraries, but hang in there.\n",
    "\n",
    "To keep things simple and interesting, we will make use of the same data above, which fits into memory. Linear models are created using `LinearRegressor`. We will need to do the following:\n",
    "1. Create Feature Columns\n",
    "1. Create Training, Validation, and Test Input Functions\n",
    "1. Create Estimator\n",
    "1. Train Estimator\n",
    "1. Evaluate Estimator\n",
    "1. Use Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import tensorflow\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "crim = tf.feature_column.numeric_column('crim', dtype=tf.float64, shape=())\n",
    "zn = tf.feature_column.numeric_column('zn', dtype=tf.float64, shape=())\n",
    "indus = tf.feature_column.numeric_column('indus', dtype=tf.float64, shape=())\n",
    "chas = tf.feature_column.numeric_column('chas', dtype=tf.int64, shape=())\n",
    "nox = tf.feature_column.numeric_column('nox', dtype=tf.float64, shape=())\n",
    "rm = tf.feature_column.numeric_column('rm', dtype=tf.float64, shape=())\n",
    "age = tf.feature_column.numeric_column('age', dtype=tf.float64, shape=())\n",
    "dis = tf.feature_column.numeric_column('dis', dtype=tf.float64, shape=())\n",
    "rad = tf.feature_column.numeric_column('rad', dtype=tf.int64, shape=())\n",
    "tax = tf.feature_column.numeric_column('tax', dtype=tf.int64, shape=())\n",
    "ptratio = tf.feature_column.numeric_column('ptratio', dtype=tf.float64, shape=())\n",
    "black = tf.feature_column.numeric_column('black', dtype=tf.float64, shape=())\n",
    "lstat = tf.feature_column.numeric_column('lstat', dtype=tf.float64, shape=())\n",
    "\n",
    "feature_cols = [crim, zn, indus, chas, nox, rm, age, dis, rad, tax, ptratio, black, lstat]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = ['crim', 'zn', 'indus', 'chas', 'nox', 'rm', 'age', 'dis', 'rad', 'tax', 'ptratio', 'black', 'lstat']\n",
    "label_name = 'medv'\n",
    "\n",
    "features_ndarray = boston_df[feature_names]\n",
    "label_ndarray = boston_df[label_name]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_ndarray, label_ndarray, random_state=0, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training input function\n",
    "def train_input():\n",
    "    _dataset = tf.data.Dataset.from_tensor_slices(({'crim': X_train['crim'], \n",
    "                                                   'zn': X_train['zn'], \n",
    "                                                   'indus': X_train['indus'],\n",
    "                                                   'chas': X_train['chas'],\n",
    "                                                   'nox': X_train['nox'],\n",
    "                                                   'rm': X_train['rm'],\n",
    "                                                   'age': X_train['age'],\n",
    "                                                   'dis': X_train['dis'],\n",
    "                                                   'rad': X_train['rad'],\n",
    "                                                   'tax': X_train['tax'],\n",
    "                                                   'ptratio': X_train['ptratio'],\n",
    "                                                   'black': X_train['black'],\n",
    "                                                   'lstat': X_train['lstat']\n",
    "                                                  }, y_train))\n",
    "    dataset = _dataset.batch(16)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation input function\n",
    "def val_input():\n",
    "    _dataset = tf.data.Dataset.from_tensor_slices(({'crim': X_test['crim'], \n",
    "                                                   'zn': X_test['zn'], \n",
    "                                                   'indus': X_test['indus'],\n",
    "                                                   'chas': X_test['chas'],\n",
    "                                                   'nox': X_test['nox'],\n",
    "                                                   'rm': X_test['rm'],\n",
    "                                                   'age': X_test['age'],\n",
    "                                                   'dis': X_test['dis'],\n",
    "                                                   'rad': X_test['rad'],\n",
    "                                                   'tax': X_test['tax'],\n",
    "                                                   'ptratio': X_test['ptratio'],\n",
    "                                                   'black': X_test['black'],\n",
    "                                                   'lstat': X_test['lstat']\n",
    "                                                  }, y_test))\n",
    "    dataset = _dataset.batch(16)\n",
    "    iterator = dataset.make_one_shot_iterator()\n",
    "    features, labels = iterator.get_next()\n",
    "    return features, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Estimator\n",
    "\n",
    "When we create our `Estimator`, we have the option of specifying our optimizer. The optimizer determines how **gradient descent** is carried out during training. We are able to specify things like our `learning rate` using the optimizer. If we do not specify an optimizer, a default is used, along with a default learning rate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmpip0k2qmk\n",
      "INFO:tensorflow:Using config: {'_model_dir': '/var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmpip0k2qmk', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x1a3790aa90>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    "optimizer = tf.train.FtrlOptimizer(learning_rate=0.1, l1_regularization_strength=0.9)\n",
    "estimator = tf.estimator.LinearRegressor(feature_columns=feature_cols, optimizer=optimizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmpip0k2qmk/model.ckpt.\n",
      "INFO:tensorflow:loss = 10394.72, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 15 into /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmpip0k2qmk/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 284.82892.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.canned.linear.LinearRegressor at 0x1a39c78f98>"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator.train(input_fn=train_input, steps=5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-03-18:17:21\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmp01npc0w_/model.ckpt-15\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-03-18:17:22\n",
      "INFO:tensorflow:Saving dict for global step 15: average_loss = 99.76284, global_step = 15, loss = 1549.6495\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-10-03-18:17:22\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmp01npc0w_/model.ckpt-15\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-10-03-18:17:23\n",
      "INFO:tensorflow:Saving dict for global step 15: average_loss = 72.69981, global_step = 15, loss = 1038.5687\n"
     ]
    }
   ],
   "source": [
    "train_e = estimator.evaluate(input_fn=train_input)\n",
    "test_e = estimator.evaluate(input_fn=val_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_loss': 99.76284, 'loss': 1549.6495, 'global_step': 15}\n"
     ]
    }
   ],
   "source": [
    "print(train_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'average_loss': 72.69981, 'loss': 1038.5687, 'global_step': 15}\n"
     ]
    }
   ],
   "source": [
    "print(test_e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /var/folders/2d/49w9fshj6ljb1kjldptz0w7h0000gn/T/tmpip0k2qmk/model.ckpt-15\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "[20.092049  20.231483   6.9307528 16.890944  18.189425  17.180819\n",
      " 17.975758   7.4399843 18.447449  18.416367  17.567406  18.895447\n",
      " 22.23371   18.209578  18.928755  21.986542  18.023266  18.199894\n",
      " 19.886023  19.127634  18.94459   18.019047  13.781283  18.381908\n",
      "  1.8663982 18.048704  20.672987  24.861275  17.926315  18.481607\n",
      " 18.71885   19.898882  16.923288  18.79068   18.12455   19.885622\n",
      " 19.870726  16.906908  19.900043  18.466372  19.114716  22.94035\n",
      " 20.678795  18.816011  19.837313  20.049385  19.070826  23.526049\n",
      " 18.463333  13.484063  19.955206  17.966341  18.143766  14.274814\n",
      " 18.398468  17.748072  18.452711  13.898594  25.591286  19.351114\n",
      " 18.602228  24.615936  14.767889  19.046732  15.301056  17.88453\n",
      " 18.316454  19.19998   24.669376   5.1878414 18.456377  17.845366\n",
      "  3.34915   19.691593  18.334757  15.839528  18.831543  19.372566\n",
      " 18.799217  18.292925  20.039919  14.001649  19.2955    18.854633\n",
      " 20.545063  23.000977  18.497972  19.67532   19.549816  19.437422\n",
      "  4.806756  24.571571  21.530094  17.644442  18.881943  18.667862\n",
      " 18.016937  19.284716  18.081383  19.022959 ]\n"
     ]
    }
   ],
   "source": [
    "preds = estimator.predict(input_fn=val_input)\n",
    "predictions = np.array([item['predictions'][0] for item in preds])\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE = 8.52641484618118\n"
     ]
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, predictions)\n",
    "rmse = math.sqrt(mse)\n",
    "print('RMSE = {}'.format(rmse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
